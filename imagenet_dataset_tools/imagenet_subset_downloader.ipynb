{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4d5342",
   "metadata": {},
   "source": [
    "# ImageNet Subset Downloader\n",
    "\n",
    "This notebook helps you download and setup ImageNet subset datasets for experimenting with ResNet50 training.\n",
    "\n",
    "## Available Datasets:\n",
    "- **Tiny ImageNet**: 200 classes, 64x64 images, ~240MB\n",
    "- **Imagenette**: 10 classes, 320x320 images, ~300MB\n",
    "- **ImageWoof**: 10 dog breeds, 320x320 images, ~300MB\n",
    "\n",
    "Perfect for quick experiments and testing your training pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f341b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_with_progress(url, filename, progress_widget=None):\n",
    "    \"\"\"Download file with progress indication\"\"\"\n",
    "    print(f\"üì• Downloading {filename}...\")\n",
    "    \n",
    "    def progress_hook(count, block_size, total_size):\n",
    "        if progress_widget and total_size > 0:\n",
    "            percent = min(100, int(count * block_size * 100 / total_size))\n",
    "            progress_widget.value = percent\n",
    "            progress_widget.description = f\"{percent}%\"\n",
    "        elif count % 100 == 0:  # Print every 100 blocks if no widget\n",
    "            if total_size > 0:\n",
    "                percent = int(count * block_size * 100 / total_size)\n",
    "                print(f\"   Progress: {percent}%\")\n",
    "    \n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, filename, progress_hook)\n",
    "        if progress_widget:\n",
    "            progress_widget.value = 100\n",
    "            progress_widget.description = \"Complete!\"\n",
    "        print(f\"‚úÖ Download completed: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7811e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_archive(archive_path, extract_to):\n",
    "    \"\"\"Extract archive file\"\"\"\n",
    "    print(f\"üì¶ Extracting {archive_path}...\")\n",
    "    \n",
    "    try:\n",
    "        if archive_path.endswith('.zip'):\n",
    "            with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_to)\n",
    "        elif archive_path.endswith(('.tar.gz', '.tgz')):\n",
    "            with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "                tar.extractall(extract_to)\n",
    "        \n",
    "        print(\"‚úÖ Extraction completed\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Extraction failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb9ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_tiny_imagenet_val(tiny_imagenet_path):\n",
    "    \"\"\"Organize Tiny ImageNet validation data\"\"\"\n",
    "    val_dir = tiny_imagenet_path / \"val\"\n",
    "    val_annotations = val_dir / \"val_annotations.txt\"\n",
    "    \n",
    "    if not val_annotations.exists():\n",
    "        print(\"‚ö†Ô∏è Validation annotations not found\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîß Organizing validation data...\")\n",
    "    \n",
    "    # Read validation annotations\n",
    "    annotations = {}\n",
    "    with open(val_annotations, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                filename = parts[0]\n",
    "                class_name = parts[1]\n",
    "                annotations[filename] = class_name\n",
    "    \n",
    "    # Create class directories and move images\n",
    "    val_images_dir = val_dir / \"images\"\n",
    "    if val_images_dir.exists():\n",
    "        for class_name in set(annotations.values()):\n",
    "            class_dir = val_dir / class_name\n",
    "            class_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        for image_file in val_images_dir.glob(\"*.JPEG\"):\n",
    "            if image_file.name in annotations:\n",
    "                class_name = annotations[image_file.name]\n",
    "                target_dir = val_dir / class_name\n",
    "                target_path = target_dir / image_file.name\n",
    "                if not target_path.exists():\n",
    "                    shutil.move(str(image_file), str(target_path))\n",
    "        \n",
    "        # Remove empty images directory\n",
    "        if val_images_dir.exists() and not any(val_images_dir.iterdir()):\n",
    "            val_images_dir.rmdir()\n",
    "        \n",
    "        print(\"‚úÖ Validation data organized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ba08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiny_imagenet(progress_widget=None):\n",
    "    \"\"\"Download and setup Tiny ImageNet\"\"\"\n",
    "    print(\"üéØ Downloading Tiny ImageNet Dataset\")\n",
    "    print(\"   ‚Ä¢ 200 classes from ImageNet\")\n",
    "    print(\"   ‚Ä¢ 64x64 pixel images\")\n",
    "    print(\"   ‚Ä¢ ~240MB download size\")\n",
    "    print(\"   ‚Ä¢ Perfect for quick experiments\")\n",
    "    \n",
    "    # Setup paths\n",
    "    datasets_dir = Path(\"../datasets\")\n",
    "    datasets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    zip_file = datasets_dir / \"tiny-imagenet-200.zip\"\n",
    "    extract_dir = datasets_dir / \"tiny-imagenet-200\"\n",
    "    \n",
    "    # Download if not exists\n",
    "    if not zip_file.exists():\n",
    "        url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "        if not download_with_progress(url, zip_file, progress_widget):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ File already downloaded\")\n",
    "    \n",
    "    # Extract if not exists\n",
    "    if not extract_dir.exists():\n",
    "        if not extract_archive(zip_file, datasets_dir):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ Already extracted\")\n",
    "    \n",
    "    # Organize validation data\n",
    "    organize_tiny_imagenet_val(extract_dir)\n",
    "    \n",
    "    # Verify dataset\n",
    "    train_dir = extract_dir / \"train\"\n",
    "    val_dir = extract_dir / \"val\"\n",
    "    \n",
    "    if train_dir.exists() and val_dir.exists():\n",
    "        train_classes = len([d for d in train_dir.iterdir() if d.is_dir()])\n",
    "        val_classes = len([d for d in val_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        print(f\"‚úÖ Dataset ready!\")\n",
    "        print(f\"   üìÅ Location: {extract_dir}\")\n",
    "        print(f\"   üìä Training classes: {train_classes}\")\n",
    "        print(f\"   üìä Validation classes: {val_classes}\")\n",
    "        \n",
    "        return extract_dir\n",
    "    else:\n",
    "        print(\"‚ùå Dataset verification failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aea01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imagenette(progress_widget=None):\n",
    "    \"\"\"Download Imagenette 320px version\"\"\"\n",
    "    print(\"üéØ Downloading Imagenette Dataset (320px)\")\n",
    "    print(\"   ‚Ä¢ 10 classes from ImageNet\")\n",
    "    print(\"   ‚Ä¢ 320x320 pixel images\")\n",
    "    print(\"   ‚Ä¢ ~300MB download size\")\n",
    "    print(\"   ‚Ä¢ Great for quick training tests\")\n",
    "    \n",
    "    # Setup paths\n",
    "    datasets_dir = Path(\"../datasets\")\n",
    "    datasets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    tgz_file = datasets_dir / \"imagenette2-320.tgz\"\n",
    "    extract_dir = datasets_dir / \"imagenette2-320\"\n",
    "    \n",
    "    # Download if not exists\n",
    "    if not tgz_file.exists():\n",
    "        url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz\"\n",
    "        if not download_with_progress(url, tgz_file, progress_widget):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ File already downloaded\")\n",
    "    \n",
    "    # Extract if not exists\n",
    "    if not extract_dir.exists():\n",
    "        if not extract_archive(tgz_file, datasets_dir):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ Already extracted\")\n",
    "    \n",
    "    # Verify dataset\n",
    "    train_dir = extract_dir / \"train\"\n",
    "    val_dir = extract_dir / \"val\"\n",
    "    \n",
    "    if train_dir.exists() and val_dir.exists():\n",
    "        train_classes = len([d for d in train_dir.iterdir() if d.is_dir()])\n",
    "        val_classes = len([d for d in val_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        print(f\"‚úÖ Dataset ready!\")\n",
    "        print(f\"   üìÅ Location: {extract_dir}\")\n",
    "        print(f\"   üìä Training classes: {train_classes}\")\n",
    "        print(f\"   üìä Validation classes: {val_classes}\")\n",
    "        \n",
    "        # Show class names\n",
    "        if train_classes == 10:\n",
    "            print(\"   üè∑Ô∏è Classes: tench, English springer, cassette player, chain saw,\")\n",
    "            print(\"              church, French horn, garbage truck, gas pump, golf ball, parachute\")\n",
    "        \n",
    "        return extract_dir\n",
    "    else:\n",
    "        print(\"‚ùå Dataset verification failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b939ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imagewoof(progress_widget=None):\n",
    "    \"\"\"Download ImageWoof 320px version\"\"\"\n",
    "    print(\"üéØ Downloading ImageWoof Dataset (320px)\")\n",
    "    print(\"   ‚Ä¢ 10 dog breeds from ImageNet\")\n",
    "    print(\"   ‚Ä¢ 320x320 pixel images\")\n",
    "    print(\"   ‚Ä¢ ~300MB download size\")\n",
    "    print(\"   ‚Ä¢ Challenging classification task\")\n",
    "    \n",
    "    # Setup paths\n",
    "    datasets_dir = Path(\"../datasets\")\n",
    "    datasets_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    tgz_file = datasets_dir / \"imagewoof2-320.tgz\"\n",
    "    extract_dir = datasets_dir / \"imagewoof2-320\"\n",
    "    \n",
    "    # Download if not exists\n",
    "    if not tgz_file.exists():\n",
    "        url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz\"\n",
    "        if not download_with_progress(url, tgz_file, progress_widget):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ File already downloaded\")\n",
    "    \n",
    "    # Extract if not exists\n",
    "    if not extract_dir.exists():\n",
    "        if not extract_archive(tgz_file, datasets_dir):\n",
    "            return None\n",
    "    else:\n",
    "        print(\"‚úÖ Already extracted\")\n",
    "    \n",
    "    # Verify dataset\n",
    "    train_dir = extract_dir / \"train\"\n",
    "    val_dir = extract_dir / \"val\"\n",
    "    \n",
    "    if train_dir.exists() and val_dir.exists():\n",
    "        train_classes = len([d for d in train_dir.iterdir() if d.is_dir()])\n",
    "        val_classes = len([d for d in val_dir.iterdir() if d.is_dir()])\n",
    "        \n",
    "        print(f\"‚úÖ Dataset ready!\")\n",
    "        print(f\"   üìÅ Location: {extract_dir}\")\n",
    "        print(f\"   üìä Training classes: {train_classes}\")\n",
    "        print(f\"   üìä Validation classes: {val_classes}\")\n",
    "        \n",
    "        # Show class names\n",
    "        if train_classes == 10:\n",
    "            print(\"   üè∑Ô∏è Dog breeds: Australian terrier, Border terrier, Samoyed, Beagle,\")\n",
    "            print(\"                  Shih-Tzu, English foxhound, Rhodesian ridgeback, Dingo, Golden retriever, Old English sheepdog\")\n",
    "        \n",
    "        return extract_dir\n",
    "    else:\n",
    "        print(\"‚ùå Dataset verification failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43539b8d",
   "metadata": {},
   "source": [
    "## Interactive Dataset Downloader\n",
    "\n",
    "Use the widget below to select and download your preferred dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c1dafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0196e5c73cf44809c04caf6eac23eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üöÄ Select and Download Dataset</h3>'), Dropdown(description='Dataset:', options=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive downloader widget\n",
    "dataset_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Tiny ImageNet (200 classes, 64x64, ~240MB)', 'tiny'),\n",
    "        ('Imagenette (10 classes, 320x320, ~300MB)', 'imagenette'),\n",
    "        ('ImageWoof (10 dog breeds, 320x320, ~300MB)', 'imagewoof')\n",
    "    ],\n",
    "    value='tiny',\n",
    "    description='Dataset:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='Download Dataset',\n",
    "    button_style='success',\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "progress_bar = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Ready',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#2196F3'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_download_click(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Reset progress bar\n",
    "        progress_bar.value = 0\n",
    "        progress_bar.description = \"Starting...\"\n",
    "        \n",
    "        dataset_type = dataset_selector.value\n",
    "        \n",
    "        if dataset_type == 'tiny':\n",
    "            result = download_tiny_imagenet(progress_bar)\n",
    "        elif dataset_type == 'imagenette':\n",
    "            result = download_imagenette(progress_bar)\n",
    "        elif dataset_type == 'imagewoof':\n",
    "            result = download_imagewoof(progress_bar)\n",
    "        \n",
    "        if result:\n",
    "            progress_bar.bar_style = 'success'\n",
    "            print(\"\\nüéâ Download completed successfully!\")\n",
    "            print(f\"\\nüìã Next steps:\")\n",
    "            print(f\"   1. Go back to main folder: cd ..\")\n",
    "            print(f\"   2. Test setup: python quick_test.py\")\n",
    "            print(f\"   3. Run learning rate finder\")\n",
    "            print(f\"   4. Start training!\")\n",
    "        else:\n",
    "            progress_bar.bar_style = 'danger'\n",
    "            progress_bar.description = \"Failed\"\n",
    "\n",
    "download_button.on_click(on_download_click)\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üöÄ Select and Download Dataset</h3>\"),\n",
    "    dataset_selector,\n",
    "    download_button,\n",
    "    progress_bar,\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d87d11",
   "metadata": {},
   "source": [
    "## Dataset Information Summary\n",
    "\n",
    "After downloading, here's what you'll have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6faa275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Available Datasets:\n",
      "==================================================\n",
      "üìÅ No datasets found. Use the downloader above to get started!\n"
     ]
    }
   ],
   "source": [
    "def show_dataset_info():\n",
    "    \"\"\"Display information about available datasets\"\"\"\n",
    "    datasets_dir = Path(\"../datasets\")\n",
    "    \n",
    "    if not datasets_dir.exists():\n",
    "        print(\"üìÅ No datasets folder found yet. Download a dataset first!\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä Available Datasets:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check for Tiny ImageNet\n",
    "    tiny_path = datasets_dir / \"tiny-imagenet-200\"\n",
    "    if tiny_path.exists():\n",
    "        train_classes = len([d for d in (tiny_path / \"train\").iterdir() if d.is_dir()])\n",
    "        print(f\"‚úÖ Tiny ImageNet\")\n",
    "        print(f\"   üìÅ Path: {tiny_path}\")\n",
    "        print(f\"   üìä Classes: {train_classes}\")\n",
    "        print(f\"   üñºÔ∏è Image size: 64x64\")\n",
    "        print()\n",
    "    \n",
    "    # Check for Imagenette\n",
    "    imagenette_path = datasets_dir / \"imagenette2-320\"\n",
    "    if imagenette_path.exists():\n",
    "        train_classes = len([d for d in (imagenette_path / \"train\").iterdir() if d.is_dir()])\n",
    "        print(f\"‚úÖ Imagenette\")\n",
    "        print(f\"   üìÅ Path: {imagenette_path}\")\n",
    "        print(f\"   üìä Classes: {train_classes}\")\n",
    "        print(f\"   üñºÔ∏è Image size: 320x320\")\n",
    "        print()\n",
    "    \n",
    "    # Check for ImageWoof\n",
    "    imagewoof_path = datasets_dir / \"imagewoof2-320\"\n",
    "    if imagewoof_path.exists():\n",
    "        train_classes = len([d for d in (imagewoof_path / \"train\").iterdir() if d.is_dir()])\n",
    "        print(f\"‚úÖ ImageWoof\")\n",
    "        print(f\"   üìÅ Path: {imagewoof_path}\")\n",
    "        print(f\"   üìä Classes: {train_classes}\")\n",
    "        print(f\"   üñºÔ∏è Image size: 320x320\")\n",
    "        print()\n",
    "    \n",
    "    if not any([(tiny_path).exists(), (imagenette_path).exists(), (imagewoof_path).exists()]):\n",
    "        print(\"üìÅ No datasets found. Use the downloader above to get started!\")\n",
    "\n",
    "# Run the function\n",
    "show_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3258e",
   "metadata": {},
   "source": [
    "## Training Commands Generator\n",
    "\n",
    "Once you've downloaded a dataset, use this to generate the appropriate training commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_commands():\n",
    "    \"\"\"Generate training commands for available datasets\"\"\"\n",
    "    datasets_dir = Path(\"../datasets\")\n",
    "    \n",
    "    available_datasets = []\n",
    "    if (datasets_dir / \"tiny-imagenet-200\").exists():\n",
    "        available_datasets.append((\"tiny-imagenet-200\", \"Tiny ImageNet\", 64, 200))\n",
    "    if (datasets_dir / \"imagenette2-320\").exists():\n",
    "        available_datasets.append((\"imagenette2-320\", \"Imagenette\", 224, 10))\n",
    "    if (datasets_dir / \"imagewoof2-320\").exists():\n",
    "        available_datasets.append((\"imagewoof2-320\", \"ImageWoof\", 224, 10))\n",
    "    \n",
    "    if not available_datasets:\n",
    "        print(\"‚ùå No datasets found. Download one first!\")\n",
    "        return\n",
    "    \n",
    "    print(\"üöÄ Training Commands for Your Datasets\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for folder, name, img_size, num_classes in available_datasets:\n",
    "        print(f\"\\nüìä {name} ({img_size}x{img_size}, {num_classes} classes)\")\n",
    "        print(f\"üìÅ Dataset: datasets/{folder}\")\n",
    "        \n",
    "        # Determine parameters based on dataset\n",
    "        if img_size == 64:  # Tiny ImageNet\n",
    "            batch_size = 256\n",
    "            epochs = 50\n",
    "            lr = \"1e-2\"\n",
    "        else:  # Full size images\n",
    "            batch_size = 128\n",
    "            epochs = 20\n",
    "            lr = \"3e-3\"\n",
    "        \n",
    "        print(f\"\\nüíª Commands (from main project folder):\")\n",
    "        print(f\"   # Quick test (2 epochs)\")\n",
    "        print(f\"   python train_imagenet.py --data-dir datasets/{folder} --epochs 2 --batch-size 32\")\n",
    "        \n",
    "        print(f\"\\n   # Full training\")\n",
    "        print(f\"   python train_imagenet.py --data-dir datasets/{folder} --epochs {epochs} --batch-size {batch_size} --lr {lr}\")\n",
    "        \n",
    "        if num_classes == 10:  # Imagenette/ImageWoof\n",
    "            print(f\"\\n   # With pretrained weights (recommended)\")\n",
    "            print(f\"   python train_imagenet.py --data-dir datasets/{folder} --epochs {epochs//2} --batch-size {batch_size} --lr {lr} --pretrained\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Generate commands\n",
    "generate_training_commands()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d7074",
   "metadata": {},
   "source": [
    "## üéØ Quick Start Summary\n",
    "\n",
    "1. **Use the downloader above** to get your preferred dataset\n",
    "2. **Go back to main folder**: `cd ..`\n",
    "3. **Test your setup**: `python quick_test.py`\n",
    "        \"4. **Find optimal learning rate**: `cd ../lr_optimization && jupyter notebook learning_rate_finder.ipynb`\\\\n\",\n",
    "5. **Start training** with the generated commands above\n",
    "\n",
    "Happy training! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e264b4",
   "metadata": {},
   "source": [
    "### ‚úÖ Verify dataset path for training\n",
    "\n",
    "Use the next cell to print the absolute path to Tiny-ImageNet and confirm the `train/` and `val/` folders exist. If you downloaded via this notebook, it will be under `../datasets/tiny-imagenet-200` relative to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b193eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Tiny-ImageNet location and structure\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = Path.cwd()\n",
    "# Notebook lives in imagenet_dataset_tools/, datasets are one level up in ../datasets\n",
    "tiny_path = (nb_dir / \"../datasets/tiny-imagenet-200\").resolve()\n",
    "print(\"Notebook dir:\", nb_dir)\n",
    "print(\"Expected Tiny-ImageNet:\", tiny_path)\n",
    "print(\"Exists:\", tiny_path.exists())\n",
    "print(\"train/ exists:\", (tiny_path/\"train\").exists())\n",
    "print(\"val/ exists:\", (tiny_path/\"val\").exists())\n",
    "\n",
    "# If you want to train from tiny_imagenet_training folder using --data ./dataset/tiny-imagenet-200\n",
    "# create a symlink there pointing to this datasets copy (optional convenience)\n",
    "proj_root = (nb_dir / \"..\").resolve()\n",
    "train_pkg_dir = proj_root / \"tiny_imagenet_training\"\n",
    "cli_expected = train_pkg_dir / \"dataset/tiny-imagenet-200\"\n",
    "print(\"\\nCLI expected (example):\", cli_expected)\n",
    "\n",
    "try:\n",
    "    if tiny_path.exists() and not cli_expected.exists():\n",
    "        (train_pkg_dir / \"dataset\").mkdir(exist_ok=True)\n",
    "        cli_expected.symlink_to(tiny_path)\n",
    "        print(\"Created symlink:\", cli_expected, \"->\", tiny_path)\n",
    "    elif cli_expected.exists():\n",
    "        print(\"Symlink or folder already present:\", cli_expected)\n",
    "except Exception as e:\n",
    "    print(\"Symlink creation skipped:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
