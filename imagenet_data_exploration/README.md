# ImageNet Dataset Explorer ğŸ”

## ğŸ“‹ Overview

A comprehensive Jupyter notebook for exploring and analyzing the ImageNet Object Localization Challenge dataset. This tool provides step-by-step analysis, visualization, and preprocessing utilities for computer vision projects.

**File Location:** `/home/ubuntu/user/shankar/TSAI_ERAv4_mini_capstone_S9/TSAI_ERA_v4_mini_capstone_S9/imagenet_data_exploration/imagenet_dataset_explorer.ipynb`

---

## ğŸ¯ Dataset Information

- **Source**: Kaggle ImageNet Object Localization Challenge
- **Dataset Location**: `/home/ubuntu/Downloads/ILSVRC/`
- **Classes**: 1000 object categories
- **Task**: Object classification and localization
- **Format**: ILSVRC (ImageNet Large Scale Visual Recognition Challenge)

### ğŸ“ Expected Dataset Structure
```
ILSVRC/
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ CLS-LOC/
â”‚       â”œâ”€â”€ train/           # Training images (1000 class folders)
â”‚       â”œâ”€â”€ val/             # Validation images (50,000 images)
â”‚       â””â”€â”€ test/            # Test images (100,000 images)
â”œâ”€â”€ Annotations/
â”‚   â””â”€â”€ CLS-LOC/
â”‚       â”œâ”€â”€ train/           # Training bounding box annotations (XML)
â”‚       â””â”€â”€ val/             # Validation bounding box annotations (XML)
â””â”€â”€ ImageSets/
    â””â”€â”€ CLS-LOC/
        â”œâ”€â”€ train_cls.txt    # Training image list
        â”œâ”€â”€ val.txt          # Validation image list
        â””â”€â”€ test.txt         # Test image list
```

---

## ğŸ“š Notebook Cells Documentation

### Cell 1: Introduction and Overview (Markdown)
**Purpose**: Provides dataset overview and structure documentation.

**Content**:
- Dataset source and location
- Expected directory structure
- Task description (classification + localization)

**Output**: Documentation display with formatted structure diagram.

---

### Cell 2: Import Required Libraries (Python)
**Purpose**: Import all necessary Python libraries for data analysis and visualization.

**Libraries Imported**:
```python
import os, glob, random, xml.etree.ElementTree as ET
from pathlib import Path
from collections import Counter, defaultdict
import numpy as np, pandas as pd
import matplotlib.pyplot import plt, matplotlib.patches as patches
import seaborn as sns
from PIL import Image
from tqdm import tqdm
```

**Expected Output**:
```
âœ… Libraries imported successfully!
```

**Functionality**: Sets up the environment with plotting styles and imports for:
- File system operations
- Data manipulation (pandas, numpy)
- Image processing (PIL)
- Visualization (matplotlib, seaborn)
- XML parsing for annotations
- Progress tracking (tqdm)

---

### Cell 3: Set Dataset Paths (Python)
**Purpose**: Configure dataset paths and verify directory structure.

**Key Variables**:
- `DATASET_ROOT`: Main dataset directory
- `TRAIN_DIR`, `VAL_DIR`, `TEST_DIR`: Image directories
- `TRAIN_ANNOTATIONS_DIR`, `VAL_ANNOTATIONS_DIR`: Annotation directories
- `IMAGESETS_DIR`: Image list files directory

**Expected Output**:
```
ğŸ“ Dataset root: /home/ubuntu/Downloads/ILSVRC
ğŸ“ Data directory: /home/ubuntu/Downloads/ILSVRC/Data/CLS-LOC
ğŸ“ Annotations directory: /home/ubuntu/Downloads/ILSVRC/Annotations/CLS-LOC
ğŸ“ ImageSets directory: /home/ubuntu/Downloads/ILSVRC/ImageSets/CLS-LOC
âœ… Dataset Root: Found
âœ… Train Images: Found
âœ… Val Images: Found
âœ… Test Images: Found
âœ… Train Annotations: Found
âœ… Val Annotations: Found
âœ… ImageSets: Found
```

**Functionality**: 
- Validates dataset structure
- Reports missing components
- Sets up global path variables

---

### Cell 4: Load ImageNet Class Information (Python)
**Purpose**: Extract class information from training directory structure.

**Function**: `load_class_names()`
- Scans training directories
- Creates class mapping with synset IDs
- Assigns sequential indices

**Expected Output**:
```
ğŸ“Š Found 1000 classes

ğŸ” First 10 classes:
    1. n01440764
    2. n01443537
    3. n01484850
    4. n01491361
    5. n01494475
    6. n01496331
    7. n01498041
    8. n01514668
    9. n01514859
   10. n01518878
```

**Functionality**: Maps WordNet synset IDs to class indices for model training.

---

### Cell 5: Analyze Dataset Structure and Statistics (Python)
**Purpose**: Compute comprehensive dataset statistics.

**Function**: `analyze_dataset_structure()`
- Counts classes and images per split
- Estimates total dataset size
- Provides statistical overview

**Expected Output**:
```
ğŸ” Analyzing dataset structure...

ğŸ“Š Dataset Statistics:
==================================================
   TRAIN: 1,000 classes, 1,281,167 images
     VAL: 1,000 classes, 50,000 images
    TEST: 1,000 classes, 100,000 images
   TOTAL: 1,431,167 images
```

**Functionality**: 
- Sampling-based estimation for large datasets
- Memory-efficient counting
- Cross-split validation

---

### Cell 6: Explore Training Set Distribution (Python)
**Purpose**: Analyze image distribution across training classes.

**Function**: `analyze_training_distribution()`
- Samples classes for analysis
- Counts images per class
- Generates distribution statistics

**Expected Output**:
```
ğŸ“Š Analyzing 1000 training classes...

ğŸ“ˆ Training Set Analysis (Sample of 50 classes):
Average images per class: 1281.2
Min images per class: 732
Max images per class: 1300
Total images (sample): 64,060
```

**Visualizations**:
1. **Histogram**: Distribution of images per class
2. **Bar Chart**: Top 10 classes by image count

**Functionality**: 
- Statistical analysis of class balance
- Identifies over/under-represented classes
- Helps with sampling strategies

---

### Cell 7: Sample Image Exploration (Python)
**Purpose**: Visual exploration of dataset content.

**Function**: `display_sample_images()`
- Randomly samples classes and images
- Creates image grid visualization
- Shows image dimensions and class names

**Parameters**:
- `num_classes=4`: Number of classes to display
- `images_per_class=4`: Images per class

**Expected Output**: 4Ã—4 grid showing sample images with:
- Class synset IDs as row headers
- Image dimensions as titles
- Random representative samples

**Functionality**: 
- Quality assessment
- Visual data validation
- Class content understanding

---

### Cell 8: Analyze Image Properties (Python)
**Purpose**: Comprehensive image property analysis.

**Function**: `analyze_image_properties()`
- Samples images across multiple classes
- Analyzes technical properties
- Generates statistical distributions

**Properties Analyzed**:
- Width and height distributions
- File sizes
- Image formats (JPEG, PNG)
- Color modes (RGB, grayscale)
- Aspect ratios

**Expected Output**:
```
ğŸ“Š Image Properties Analysis (200 images):
==================================================
Width  - Min: 213, Max: 500, Mean: 384.2
Height - Min: 240, Max: 375, Mean: 289.7
File Size (KB) - Min: 8.4, Max: 187.3, Mean: 45.6
Aspect Ratio - Min: 0.67, Max: 2.41, Mean: 1.34

Formats: {'JPEG': 195, 'PNG': 5}
Modes: {'RGB': 198, 'L': 2}
```

**Visualizations**:
1. **Width Distribution**: Histogram of image widths
2. **Height Distribution**: Histogram of image heights  
3. **Aspect Ratio Distribution**: Aspect ratio spread
4. **File Size Distribution**: Storage size analysis

**Functionality**: Informs preprocessing decisions and model architecture choices.

---

### Cell 9: Calculate RGB Normalization Values (Python) ğŸ”¥
**Purpose**: Compute dataset-specific normalization statistics for model training.

**Function**: `calculate_rgb_normalization_values()`
- Samples images across multiple classes
- Calculates per-channel statistics
- Compares with ImageNet standards

**Parameters**:
- `num_samples=1000`: Images to analyze
- `sample_classes=20`: Classes to sample from

**Expected Output**:
```
ğŸ”¢ Calculating RGB normalization values...
ğŸ“Š Sampling 1000 images from 20 classes

ğŸ“Š RGB Normalization Statistics (1,000 images processed):
============================================================
ğŸ”´ Red   Channel - Mean: 0.485123, Std: 0.229456
ğŸŸ¢ Green Channel - Mean: 0.456789, Std: 0.224567
ğŸ”µ Blue  Channel - Mean: 0.406234, Std: 0.225123

ğŸ¯ PyTorch Normalization Values:
========================================
mean = [0.485123, 0.456789, 0.406234]
std  = [0.229456, 0.224567, 0.225123]

ğŸ“‹ Ready-to-use PyTorch Transform:
========================================
transforms.Normalize(
    mean=[0.485123, 0.456789, 0.406234],
    std=[0.229456, 0.224567, 0.225123]
)

ğŸ“Š Comparison with ImageNet Standard Values:
==================================================
Channel |   Your Dataset   |   ImageNet Std   |   Difference
--------|------------------|------------------|-------------
Red     | 0.485123      | 0.485000      | 0.000123
Green   | 0.456789      | 0.456000      | 0.000789
Blue    | 0.406234      | 0.406000      | 0.000234

ğŸ’¡ Recommendations:
âœ… Your dataset values are close to ImageNet standard values
âœ… You can use ImageNet normalization: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
```

**Visualizations**:
1. **RGB Channel Distributions**: Overlaid histograms for R, G, B channels
2. **Mean Comparison**: Bar chart comparing dataset vs ImageNet means
3. **Standard Deviation Comparison**: Dataset vs ImageNet standard deviations
4. **Sample Image Preview**: Shows original image before normalization

**Functionality**: 
- Essential for proper model training
- Ensures optimal convergence
- Customizable for different datasets

---

### Cell 10: Explore Validation Set (Python)
**Purpose**: Analyze validation dataset structure and content.

**Function**: `analyze_validation_set()`
- Counts validation images
- Displays sample validation images
- Checks for ground truth files

**Expected Output**:
```
ğŸ“Š Validation Set Analysis:
Total validation images: 50,000

âœ… Validation ground truth file found: /path/to/val.txt

ğŸ“„ Sample validation ground truth entries:
  ILSVRC2012_val_00000001.JPEG 65
  ILSVRC2012_val_00000002.JPEG 970
  ILSVRC2012_val_00000003.JPEG 230
```

**Visualizations**: 2Ã—4 grid of sample validation images with filenames and dimensions.

**Functionality**: 
- Validates test data availability
- Checks ground truth alignment
- Ensures evaluation readiness

---

### Cell 11: Explore Annotations (Bounding Boxes) (Python)
**Purpose**: Parse and visualize object detection annotations.

**Functions**:
- `parse_annotation_xml()`: Parses XML annotation files
- `explore_annotations()`: Visualizes bounding boxes

**Expected Output**:
```
âœ… Training annotations directory found
ğŸ“„ Found 431 annotation files in class 'n02916936'

ğŸ“Š Annotation Analysis (Sample of 6 files):
Objects per image - Min: 1, Max: 3, Mean: 1.5
```

**Visualizations**: 2Ã—3 grid showing images with overlaid red bounding boxes and object labels.

**Functionality**: 
- Object detection task preparation
- Annotation quality assessment
- Localization ground truth validation

---

### Cell 12: Improved Annotation Visualization (Python)
**Purpose**: Enhanced annotation exploration with robust image matching.

**Functions**:
- `find_matching_image()`: Flexible image file matching
- `explore_annotations_improved()`: Robust annotation visualization

**Expected Output**:
```
âœ… Training annotations directory found
ğŸ“„ Checking class 'n01440764' - 431 annotation files
âœ… Found 6 matching image-annotation pairs in class 'n01440764'

ğŸ“Š Annotation Analysis (Class: n01440764, 6 files):
Objects per image - Min: 1, Max: 1, Mean: 1.0

ğŸ“‹ Object Types Found:
  â€¢ tench: 4 instances
  â€¢ goldfish: 2 instances
```

**Advanced Features**:
- Multiple file extension support
- Cross-class fallback mechanism
- Detailed error reporting
- Object type statistics

**Functionality**: Handles real-world dataset inconsistencies and naming variations.

---

### Cell 13: Debug Annotation Matching (Python)
**Purpose**: Diagnostic tool for annotation-image alignment issues.

**Function**: `debug_annotation_image_matching()`
- Identifies file matching problems
- Reports directory structure issues
- Suggests solutions for common problems

**Expected Output**:
```
ğŸ” Debugging annotation and image file matching...
ğŸ” Debugging class: n01440764
ğŸ“„ Found 431 XML annotation files
ğŸ“ Image directory: /path/to/train/n01440764
ğŸ“ Image directory exists: True
ğŸ–¼ï¸ Found 1300 image files

ğŸ” Checking first 3 annotation files:
  ğŸ“„ n01440764_18.xml -> ğŸ–¼ï¸ n01440764_18.JPEG
      Image exists: True
```

**Functionality**: 
- Troubleshooting tool
- Validates dataset integrity
- Identifies structural problems

---

### Cell 14: Dataset Summary (Python)
**Purpose**: Comprehensive dataset overview and recommendations.

**Function**: `print_dataset_summary()`
- Summarizes found/missing components
- Provides quick statistics
- Lists potential use cases
- Suggests next steps

**Expected Output**:
```
ğŸ¯ ImageNet Dataset Exploration Summary
============================================================
âœ… Found Components (6):
   â€¢ Training Images
   â€¢ Validation Images
   â€¢ Test Images
   â€¢ Training Annotations
   â€¢ Validation Annotations
   â€¢ ImageSets

ğŸ“Š Quick Stats:
   â€¢ Training classes: 1000
   â€¢ Validation images: 50,000
   â€¢ Test images: 100,000

ğŸ¯ Dataset is ready for:
   â€¢ Image classification tasks
   â€¢ Object detection/localization tasks
   â€¢ Transfer learning experiments
   â€¢ Computer vision research

ğŸ“š Next Steps:
   1. Load specific classes for your task
   2. Implement data loaders (PyTorch/TensorFlow)
   3. Apply data augmentation techniques
   4. Train/fine-tune deep learning models
   5. Evaluate on validation/test sets
```

**Functionality**: Provides project planning guidance and readiness assessment.

---

### Cell 15: Usage Examples (Markdown)
**Purpose**: Code examples for integrating dataset into ML projects.

**Content**:
- PyTorch DataLoader examples
- Custom dataset class templates
- Transform pipeline examples
- Best practices

---

## ğŸš€ Project Usage Guide

### 1. Image Classification Projects

**Basic Setup**:
```python
from torchvision import datasets, transforms

# Use calculated normalization values from Cell 9
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485123, 0.456789, 0.406234],  # From notebook output
        std=[0.229456, 0.224567, 0.225123]    # From notebook output
    )
])

train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=transform)
train_loader = torch.utils.data.DataLoader(
    train_dataset, batch_size=32, shuffle=True, num_workers=4
)
```

**Applications**:
- Image classification competitions
- Transfer learning experiments
- Model architecture research
- Performance benchmarking

### 2. Object Detection Projects

**Annotation Processing**:
```python
# Use functions from Cells 11-12
annotations = []
for xml_file in xml_files:
    ann = parse_annotation_xml(xml_file)
    if ann:
        annotations.append(ann)
```

**Applications**:
- YOLO/R-CNN training
- Object localization tasks
- Multi-object detection
- Bounding box regression

### 3. Transfer Learning Projects

**Pretrained Model Fine-tuning**:
```python
import torchvision.models as models

# Load pretrained model
model = models.resnet50(pretrained=True)
model.fc = torch.nn.Linear(model.fc.in_features, num_classes)

# Use dataset statistics for optimal training
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

**Applications**:
- Domain adaptation
- Few-shot learning
- Feature extraction
- Model compression

### 4. Data Augmentation Strategies

**Based on Image Properties (Cell 8)**:
```python
# Use insights from image property analysis
transform_train = transforms.Compose([
    transforms.Resize((256, 256)),  # Based on mean dimensions
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=calculated_means, std=calculated_stds)
])
```

### 5. Model Evaluation Framework

**Validation Pipeline**:
```python
def evaluate_model(model, val_loader, device):
    model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    accuracy = 100 * correct / total
    return accuracy
```

---

## ğŸ“Š Performance Optimization Tips

### 1. Memory Management
- Use `num_workers > 0` in DataLoader for parallel loading
- Implement memory-efficient data loading for large datasets
- Consider using `pin_memory=True` for GPU training

### 2. Training Optimization
- Use calculated normalization values for faster convergence
- Implement learning rate scheduling based on dataset size
- Apply class balancing if distribution analysis shows imbalance

### 3. Monitoring and Debugging
- Use notebook visualizations to debug training issues
- Monitor annotation quality for object detection tasks
- Validate data preprocessing with sample visualization

---

## ğŸ”§ Customization Guidelines

### 1. Dataset Path Configuration
Update `DATASET_ROOT` in Cell 3 to match your dataset location:
```python
DATASET_ROOT = "/path/to/your/imagenet/dataset"
```

### 2. Sampling Parameters
Adjust analysis parameters based on computational resources:
```python
# Cell 6: Training distribution analysis
sample_size = min(100, len(train_classes))  # Reduce for faster analysis

# Cell 9: RGB normalization calculation  
calculated_means, calculated_stds = calculate_rgb_normalization_values(
    num_samples=500,    # Reduce for faster computation
    sample_classes=10   # Reduce for memory efficiency
)
```

### 3. Visualization Customization
Modify visualization parameters for different display requirements:
```python
# Cell 7: Sample image display
display_sample_images(num_classes=6, images_per_class=3)

# Cell 11: Annotation visualization
explore_annotations_improved(num_samples=12)
```

---

## ğŸ› Troubleshooting Guide

### Common Issues and Solutions

1. **Path Not Found Errors**
   - Verify dataset extraction location
   - Check directory permissions
   - Ensure complete dataset download

2. **Memory Errors**
   - Reduce sampling parameters
   - Process data in smaller batches
   - Close unused image handles

3. **Empty Visualizations**
   - Run debug cells (Cell 13) for diagnosis
   - Check image-annotation file matching
   - Verify dataset structure integrity

4. **Import Errors**
   - Install missing packages: `pip install -r requirements.txt`
   - Verify Python environment compatibility
   - Check library versions

---

## ğŸ“ˆ Expected Runtime Performance

### Analysis Times (Approximate)
- **Full notebook execution**: 10-15 minutes
- **RGB normalization calculation**: 2-3 minutes (1000 samples)
- **Image property analysis**: 1-2 minutes (200 samples)
- **Annotation exploration**: 30-60 seconds

### Resource Requirements
- **RAM**: 4-8 GB recommended
- **Storage**: 150+ GB for full ImageNet dataset
- **CPU**: Multi-core recommended for parallel processing

---

## ğŸ¯ Project Integration Examples

### Research Projects
- Compare normalization strategies using calculated values
- Analyze class distribution for sampling strategies  
- Use annotation statistics for architecture design

### Industry Applications  
- Validate dataset quality before model deployment
- Establish preprocessing pipelines for production
- Create data quality monitoring dashboards

### Educational Use
- Demonstrate dataset analysis techniques
- Teaching computer vision preprocessing
- Showcase best practices in ML workflows

---

## ğŸ“š Additional Resources

### Related Documentation
- [PyTorch ImageFolder Documentation](https://pytorch.org/vision/stable/datasets.html#imagefolder)
- [ImageNet Dataset Paper](https://www.image-net.org/papers/imagenet_cvpr09.pdf)
- [ILSVRC Competition Details](https://www.image-net.org/challenges/LSVRC/)

### Recommended Reading
- Data preprocessing best practices
- Transfer learning strategies
- Computer vision evaluation metrics

---

## ğŸ¤ Contributing

To improve this notebook:
1. Test with different dataset versions
2. Add support for additional annotation formats
3. Implement automated quality assessment
4. Extend visualization capabilities
5. Add performance profiling tools

---

**Last Updated**: October 18, 2025  
**Version**: 1.0  
**Compatibility**: Python 3.7+, PyTorch 1.7+, PIL 8.0+
- **Color analysis** - RGB channel distributions and histograms
- **Property analysis** - Brightness, contrast, aspect ratios
- **Comparative visualization** - Compare classes and splits

### ğŸ›ï¸ Interactive Tools
- **Class selector** - Dropdown to choose classes
- **Navigation controls** - Previous, Next, Random buttons
- **Split selection** - Toggle between train/validation sets
- **Real-time info** - Dynamic image and file information display

## ğŸ“‹ Requirements

### Essential
- Python 3.8+
- matplotlib (plotting)
- PIL/Pillow (image processing)
- numpy (numerical computing)
- pandas (data analysis)

### Optional
- ipywidgets (interactive features)
- seaborn (enhanced plotting)
- jupyter (notebook environment)

## ğŸ“‚ Dataset Setup

Your ImageNet dataset should be organized as:

```
imagenet/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ n01440764/    # Class folder (WordNet ID)
â”‚   â”‚   â”œâ”€â”€ image1.JPEG
â”‚   â”‚   â”œâ”€â”€ image2.JPEG
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ n01443537/
â”‚   â””â”€â”€ ...           # 1000 class folders
â””â”€â”€ val/
    â”œâ”€â”€ n01440764/
    â”‚   â”œâ”€â”€ image1.JPEG
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
```

## ğŸ® Usage Examples

### Basic Exploration
```python
# Display 6 random images from a class
display_sample_images('n01440764', num_images=6, split='train')

# Analyze image metadata
metadata = analyze_image_metadata('n01440764', max_images=50)
visualize_metadata(metadata, 'n01440764')
```

### Advanced Analysis
```python
# Analyze color properties
analyze_image_properties('n01440764', max_images=100)

# Visualize class distribution
visualize_class_distribution(max_classes=50)
```

### Interactive Exploration
Run the interactive explorer cell to get:
- Class selection dropdown
- Image navigation controls
- Real-time image information
- Seamless browsing experience

## ğŸ”§ Customization

You can modify the notebook for your specific needs:

### Adjust Sample Sizes
```python
MAX_IMAGES_PER_CLASS = 20  # Increase for more samples
FIGURE_SIZE = (20, 15)     # Larger plots
```

### Add Custom Analysis
```python
def custom_analysis(class_name):
    # Your custom analysis code here
    pass
```

### Filter Classes
```python
# Analyze only specific classes
target_classes = ['n01440764', 'n01443537', 'n01484850']
for class_name in target_classes:
    analyze_image_properties(class_name)
```

## ğŸ’¡ Tips

1. **Start Small** - Begin with a few classes to test your setup
2. **Update Paths** - Ensure the `IMAGENET_ROOT` path is correct
3. **Use Interactive Mode** - Leverage widgets for efficient browsing
4. **Save Insights** - Document interesting findings in new cells
5. **Compare Classes** - Run the same analysis on different classes
6. **Monitor Performance** - Large sample sizes may take time to process

## ğŸ› Troubleshooting

### Common Issues

**Notebook not starting:**
```bash
pip install jupyter
jupyter notebook --version
```

**Images not loading:**
- Check the `IMAGENET_ROOT` path
- Verify dataset folder structure
- Ensure image files have correct extensions

**Interactive widgets not working:**
```bash
pip install ipywidgets
jupyter nbextension enable --py widgetsnbextension
```

**Slow performance:**
- Reduce `max_images` parameters
- Analyze fewer classes at once
- Use smaller figure sizes

### Getting Help

1. Check the main project README for general setup
2. Run `cd ../setup && python test_setup.py` to verify dependencies
3. Use the organized subfolder structure for easy navigation

## ğŸ‰ Next Steps

After exploring your dataset:

1. **Identify interesting classes** for detailed analysis
2. **Compare train/val distributions** for data quality assessment
3. **Document findings** for preprocessing decisions
4. **Select representative samples** for model testing
5. **Use insights** to inform training strategy

Happy exploring! ğŸš€