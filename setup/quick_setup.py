#!/usr/bin/env python3
"""
Quick Setup Script - Updates training files for downloaded datasets
"""

from pathlib import Path
import shutil
import os
import sys

def update_dataset_paths():
    """Update dataset paths in training files"""
    
    # Change to parent directory (project root)
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    os.chdir(project_root)
    
    # Check what datasets are available
    datasets_dir = Path("datasets")
    available_datasets = []
    
    if (datasets_dir / "tiny-imagenet-200").exists():
        available_datasets.append(("tiny-imagenet-200", "Tiny ImageNet"))
    if (datasets_dir / "imagenette2-320").exists():
        available_datasets.append(("imagenette2-320", "Imagenette 320px"))
    
    if not available_datasets:
        print("❌ No datasets found. Please use dataset_tools/imagenet_subset_downloader.ipynb first!")
        return
    
    print("📁 Found datasets:")
    for i, (folder, name) in enumerate(available_datasets, 1):
        print(f"   {i}. {name} ({folder})")
    
    # Get user choice
    if len(available_datasets) == 1:
        choice = 1
        print(f"\n✅ Auto-selecting: {available_datasets[0][1]}")
    else:
        while True:
            try:
                choice = int(input(f"\nSelect dataset (1-{len(available_datasets)}): "))
                if 1 <= choice <= len(available_datasets):
                    break
                else:
                    print(f"Please enter a number between 1 and {len(available_datasets)}")
            except ValueError:
                print("Please enter a valid number")
    
    selected_folder, selected_name = available_datasets[choice - 1]
    dataset_path = datasets_dir / selected_folder
    
    print(f"\n🔧 Updating training files for {selected_name}...")
    
    # Update train_imagenet.py default path
    train_file = Path("train_imagenet.py")
    if train_file.exists():
        content = train_file.read_text()
        # Update default data directory
        updated_content = content.replace(
            'default="datasets/imagenet"',
            f'default="datasets/{selected_folder}"'
        )
        if updated_content != content:
            train_file.write_text(updated_content)
            print("   ✅ Updated train_imagenet.py")
    
    # Create a dataset config file
    config_content = f"""# Dataset Configuration
# Generated by quick_setup.py

DATASET_NAME = "{selected_name}"
DATASET_PATH = "datasets/{selected_folder}"
DATASET_TYPE = "{'tiny_imagenet' if 'tiny' in selected_folder else 'imagenette'}"

# Quick training settings
if DATASET_TYPE == "tiny_imagenet":
    RECOMMENDED_BATCH_SIZE = 256
    RECOMMENDED_EPOCHS = 50
    RECOMMENDED_LR = 1e-2
    IMAGE_SIZE = 64
    NUM_CLASSES = 200
else:  # imagenette
    RECOMMENDED_BATCH_SIZE = 128
    RECOMMENDED_EPOCHS = 20
    RECOMMENDED_LR = 3e-3
    IMAGE_SIZE = 224
    NUM_CLASSES = 10

print(f"Current dataset: {{DATASET_NAME}}")
print(f"Dataset path: {{DATASET_PATH}}")
print(f"Recommended batch size: {{RECOMMENDED_BATCH_SIZE}}")
print(f"Recommended epochs: {{RECOMMENDED_EPOCHS}}")
print(f"Recommended learning rate: {{RECOMMENDED_LR}}")
"""
    
    config_file = Path("dataset_config.py")
    config_file.write_text(config_content)
    print("   ✅ Created dataset_config.py")
    
    # Create quick test script
    test_script = f"""#!/usr/bin/env python3
\"\"\"
Quick Test Script - Verify dataset and training setup
\"\"\"

import torch
import torchvision.transforms as transforms
from pathlib import Path
import sys

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

from imagenet_dataset import get_imagenet_loaders
from imagenet_models import resnet50_imagenet

def test_dataset():
    \"\"\"Test dataset loading\"\"\"
    print("🧪 Testing dataset loading...")
    
    dataset_path = Path("datasets/{selected_folder}")
    if not dataset_path.exists():
        print(f"❌ Dataset not found at {{dataset_path}}")
        return False
    
    try:
        train_loader, val_loader = get_imagenet_loaders(
            data_dir=str(dataset_path),
            batch_size=32,  # Small batch for testing
            num_workers=2
        )
        
        # Test loading one batch
        train_batch = next(iter(train_loader))
        val_batch = next(iter(val_loader))
        
        print(f"✅ Dataset loading successful!")
        print(f"   📊 Train batch shape: {{train_batch[0].shape}}")
        print(f"   📊 Val batch shape: {{val_batch[0].shape}}")
        print(f"   🏷️ Number of classes: {{len(set(train_batch[1].tolist()))}}")
        
        return True
    except Exception as e:
        print(f"❌ Dataset loading failed: {{e}}")
        return False

def test_model():
    \"\"\"Test model creation\"\"\"
    print("\\n🧪 Testing model creation...")
    
    try:
        # Determine number of classes based on dataset
        num_classes = 200 if 'tiny' in '{selected_folder}' else 10
        
        model = resnet50_imagenet(num_classes=num_classes)
        
        # Test forward pass
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        
        # Create dummy input
        input_size = 64 if 'tiny' in '{selected_folder}' else 224
        dummy_input = torch.randn(2, 3, input_size, input_size).to(device)
        
        with torch.no_grad():
            output = model(dummy_input)
        
        print(f"✅ Model creation successful!")
        print(f"   🏗️ Model parameters: {{sum(p.numel() for p in model.parameters()):,}}")
        print(f"   📊 Output shape: {{output.shape}}")
        print(f"   💻 Device: {{device}}")
        
        return True
    except Exception as e:
        print(f"❌ Model creation failed: {{e}}")
        return False

def main():
    \"\"\"Run all tests\"\"\"
    print("🚀 Quick Setup Test for {selected_name}")
    print("=" * 50)
    
    dataset_ok = test_dataset()
    model_ok = test_model()
    
    print("\\n" + "=" * 50)
    if dataset_ok and model_ok:
        print("🎉 All tests passed! Ready to train.")
        print("\\n💡 Next steps:")
        print("   1. Run learning rate finder: cd lr_optimization && jupyter notebook learning_rate_finder.ipynb")
        print("   2. Quick test: python train_imagenet.py --epochs 2 --batch-size 32")
        print(f"   3. Full training: python train_imagenet.py --data-dir datasets/{selected_folder}")
    else:
        print("❌ Some tests failed. Please check your setup.")

if __name__ == "__main__":
    main()
"""
    
    test_file = Path("quick_test.py")
    test_file.write_text(test_script)
    print("   ✅ Created quick_test.py")
    
    print(f"\n🎉 Setup complete for {selected_name}!")
    print("\\n📋 Next steps:")
    print("   1. python quick_test.py          # Verify everything works")
    print("   2. cd lr_optimization && jupyter notebook learning_rate_finder.ipynb  # Find optimal LR")
    print("   3. python train_imagenet.py --epochs 5          # Quick training test")
    
    return dataset_path

if __name__ == "__main__":
    update_dataset_paths()